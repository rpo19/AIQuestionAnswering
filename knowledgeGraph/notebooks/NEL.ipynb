{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "encouraging-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "from pathlib import Path\n",
    "flair.cache_root = Path('../../data/flair')\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from flair.embeddings import SentenceTransformerDocumentEmbeddings\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quality-knitting",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-24 16:47:14,356 --------------------------------------------------------------------------------\n",
      "2021-04-24 16:47:14,357 The model key 'ner-fast' now maps to 'https://huggingface.co/flair/ner-english-fast' on the HuggingFace ModelHub\n",
      "2021-04-24 16:47:14,358  - The most current version of the model is automatically downloaded from there.\n",
      "2021-04-24 16:47:14,358  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/ner-fast/en-ner-fast-conll03-v0.4.pt)\n",
      "2021-04-24 16:47:14,359 --------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15b24b1757447ffb54fec845a0cae09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-24 16:48:33,378 loading file ..\\..\\data\\flair\\models\\ner-english-fast\\4c58e7191ff952c030b82db25b3694b58800b0e722ff15427f527e1631ed6142.e13c7c4664ffe2bbfa8f1f5375bd0dced866b8c1dd7ff89a6d705518abf0a611\n"
     ]
    }
   ],
   "source": [
    "# make a sentence\n",
    "sentence = Sentence('I love Berlin .')\n",
    "\n",
    "# load the NER tagger\n",
    "tagger = SequenceTagger.load('ner-fast')\n",
    "\n",
    "# run NER over sentence\n",
    "tagger.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "romantic-tracker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I love Berlin .',\n",
       " 'labels': [],\n",
       " 'entities': [{'text': 'Berlin',\n",
       "   'start_pos': 7,\n",
       "   'end_pos': 13,\n",
       "   'labels': [LOC (0.9994)]}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.to_dict(tag_type='ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "received-content",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-1.1.0.tar.gz (78 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=3.1.0 in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from sentence-transformers) (4.3.3)\n",
      "Requirement already satisfied: tqdm in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from sentence-transformers) (4.59.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: numpy in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from sentence-transformers) (0.24.1)\n",
      "Requirement already satisfied: scipy in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: nltk in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from sentence-transformers) (3.5)\n",
      "Requirement already satisfied: sentencepiece in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from sentence-transformers) (0.1.95)\n",
      "Requirement already satisfied: typing-extensions in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.11.13)\n",
      "Requirement already satisfied: packaging in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
      "Requirement already satisfied: requests in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.25.1)\n",
      "Requirement already satisfied: sacremoses in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
      "Requirement already satisfied: filelock in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: click in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from nltk->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from nltk->sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (4.0.0)\n",
      "Requirement already satisfied: six in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\universita\\magistrale\\ai\\master_proj_ai\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-1.1.0-py3-none-any.whl size=119616 sha256=9451d12dc758bf2e9dec96a1e41756b61832792fd492c0ba904b0ae9e46f61d7\n",
      "  Stored in directory: c:\\users\\marco\\appdata\\local\\pip\\cache\\wheels\\f8\\78\\10\\c076a6c3bed946c9ffe7476bf5ac8c3e0edb76b93471ee3cdf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'D:\\Universita\\MAGISTRALE\\AI\\master_proj_ai\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "documented-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "designed-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://lookup.dbpedia.org/api/search?label=Berlin&maxResults=10&format=JSON_RAW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dutch-miniature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': ['46574.086'],\n",
       " 'refCount': ['4684'],\n",
       " 'resource': ['http://dbpedia.org/resource/Berlin'],\n",
       " 'redirectlabel': ['Athens on the Spree',\n",
       "  'Berlib',\n",
       "  'Berlim',\n",
       "  'Berlin, Germany',\n",
       "  'Berlin-Zentrum',\n",
       "  'Berlin.de',\n",
       "  'Berlin (Germany)',\n",
       "  'Berlin City',\n",
       "  'Berlin Germany',\n",
       "  'Berlin State',\n",
       "  'Capital of East Germany',\n",
       "  'CityBerlin',\n",
       "  'City of Berlin',\n",
       "  'Cuisine of Berlin',\n",
       "  'DEBER',\n",
       "  'Federal State of Berlin',\n",
       "  'Historical sites in berlin',\n",
       "  'Land Berlin',\n",
       "  'Silicon Allee',\n",
       "  'Spreeathen',\n",
       "  'State of Berlin',\n",
       "  'UN/LOCODE:DEBER'],\n",
       " 'typeName': ['Settlement', 'City', 'Place', 'PopulatedPlace', 'Location'],\n",
       " 'comment': [\"Berlin (; German: [bɛʁˈliːn] ()) is the capital and largest city of Germany by both area and population. Its 3,748,148 (2018) inhabitants make it the  most populous city proper of the European Union. The city is one of Germany's 16 federal states. It is surrounded by the state of Brandenburg, and contiguous with Potsdam, Brandenburg's capital. The two cities are at the center of the Berlin-Brandenburg capital region, which is, with about six million inhabitants and an area of more than 30,000 km², Germany's third-largest metropolitan region after the Rhine-Ruhr and Rhine-Main regions.\"],\n",
       " 'label': ['Berlin'],\n",
       " 'type': ['http://dbpedia.org/ontology/Settlement',\n",
       "  'http://dbpedia.org/ontology/City',\n",
       "  'http://dbpedia.org/ontology/Place',\n",
       "  'http://dbpedia.org/ontology/PopulatedPlace',\n",
       "  'http://dbpedia.org/ontology/Location'],\n",
       " 'category': ['http://dbpedia.org/resource/Category:University_towns_in_Germany',\n",
       "  'http://dbpedia.org/resource/Category:Turkish_communities_outside_Turkey',\n",
       "  'http://dbpedia.org/resource/Category:City-states',\n",
       "  'http://dbpedia.org/resource/Category:Members_of_the_Hanseatic_League',\n",
       "  'http://dbpedia.org/resource/Category:Populated_places_established_in_the_13th_century',\n",
       "  'http://dbpedia.org/resource/Category:Capitals_in_Europe',\n",
       "  'http://dbpedia.org/resource/Category:1230s_establishments_in_the_Holy_Roman_Empire',\n",
       "  'http://dbpedia.org/resource/Category:1237_establishments_in_Europe',\n",
       "  'http://dbpedia.org/resource/Category:Berlin',\n",
       "  'http://dbpedia.org/resource/Category:German_state_capitals']}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(res.text)['docs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "utility-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = xmltodict.parse(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "micro-copying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berlin\n",
      "Tennis Borussia Berlin\n",
      "1. FC Union Berlin\n",
      "West Berlin\n",
      "East Berlin\n",
      "Humboldt University of Berlin\n",
      "Alba Berlin\n",
      "Eisbären Berlin\n",
      "Battle of Berlin\n",
      "Berlin Thunder\n",
      "Türkiyemspor Berlin\n",
      "Irving Berlin\n",
      "Technical University of Berlin\n",
      "Free University of Berlin\n",
      "Olympiastadion (Berlin)\n",
      "FC Viktoria 1889 Berlin\n",
      "Berlin, Maryland\n",
      "SCC Berlin\n",
      "Berlin University of the Arts\n",
      "Gemäldegalerie, Berlin\n",
      "Berlin, New Hampshire\n",
      "Berlin, Connecticut\n",
      "Berlin Philharmonic\n",
      "Berlin Wall\n",
      "Berlin (band)\n",
      "Berlin, Wisconsin\n",
      "Berlin Blockade\n",
      "Füchse Berlin Reinickendorf\n",
      "Berlin Schönefeld Airport\n",
      "Berlin–Dresden railway\n",
      "Air Berlin\n",
      "SV Tasmania Berlin\n",
      "Berlin Tegel Airport\n",
      "Berlin Conference\n",
      "Berlin International Film Festival\n",
      "Berlin Hauptbahnhof\n",
      "Berlin lebt 2\n",
      "SC Dynamo Berlin\n",
      "Berlin, Vermont\n",
      "Berlin–Wrocław railway\n",
      "Steve Berlin\n",
      "Berlin Ringbahn\n",
      "Wedding (Berlin)\n",
      "Trams in Berlin\n",
      "Berlin Tempelhof Airport\n",
      "Isaiah Berlin\n",
      "New Berlin, Wisconsin\n",
      "Berlin Palace\n",
      "Abby Berlin\n",
      "Wacker 04 Berlin\n",
      "SD Croatia Berlin\n",
      "Academy of Arts, Berlin\n",
      "SC Tasmania 1900 Berlin\n",
      "Berlin-Liga\n",
      "Berlin Südkreuz\n",
      "Dahlem (Berlin)\n",
      "Berlin Dutchmen\n",
      "Berlin–Magdeburg railway\n",
      "Berlin U-Bahn\n",
      "Berlin S-Bahn\n",
      "History of Berlin\n",
      "Blau-Weiß 1890 Berlin\n",
      "Berlin–Baghdad railway\n",
      "TuS Makkabi Berlin\n",
      "Berlin, New Jersey\n",
      "Berlin Circle\n",
      "Dash Berlin\n",
      "Minerva Berlin\n",
      "Berlin, Massachusetts\n",
      "Berlin outer ring\n",
      "Berlin State Library\n",
      "2016 Berlin truck attack\n",
      "Deutsche Oper Berlin\n",
      "Berlin–Szczecin railway\n",
      "Lichterfelde (Berlin)\n",
      "Börse Berlin\n",
      "Kunstgewerbemuseum Berlin\n",
      "Aggro Berlin\n",
      "Berlin Police\n",
      "New Berlin, New York\n",
      "Natural History Museum, Berlin\n",
      "Berlin: Symphony of a Metropolis\n",
      "Französisches Gymnasium Berlin\n",
      "Berlin–Lehrte railway\n",
      "Berlin Northern Railway\n",
      "Jeff Berlin\n",
      "Berlin Turnpike\n",
      "Berlin Ostbahnhof\n",
      "Zehlendorf (Berlin)\n",
      "Berlin Charter Township, Michigan\n",
      "Tennis Borussia Berlin (women)\n",
      "Rundfunk Berlin-Brandenburg\n",
      "Berlin State Museums\n",
      "Berlin–Halle railway\n",
      "Berlin, New York\n",
      "Berlin-Schöneberg station\n",
      "Berlin, New Hampshire micropolitan area\n",
      "Roman Catholic Archdiocese of Berlin\n",
      "Konzerthaus Berlin\n",
      "HTW Berlin\n"
     ]
    }
   ],
   "source": [
    "for result in obj['ArrayOfResults']['Result']:\n",
    "    print(result['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "tight-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as levenshtein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bridal-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityLinker():\n",
    "    def __init__(self):\n",
    "        self.tagger = SequenceTagger.load('ner-fast')\n",
    "        self.embedding = SentenceTransformerDocumentEmbeddings('bert-base-nli-mean-tokens')\n",
    "        self.lookup_keys = ['label', 'resource', 'comment']\n",
    "        \n",
    "    def __split_overlap(self, seq, size, overlap):\n",
    "        return [x for x in zip(*[seq[i::size-overlap] for i in range(size)])]\n",
    "    \n",
    "    def __lookup(self, phr, max_res = 10):\n",
    "        res = requests.get('https://lookup.dbpedia.org/api/search?query=Berlin&maxResults=10&format=JSON_RAW')\n",
    "        docs = eval(res.text)['docs']\n",
    "        return docs\n",
    "    \n",
    "    def __compute_relevance(self, phr, candidate_entity, question_embedding, alfa1=1, alfa2=1, alfa3=1):\n",
    "        # TODO: compute importance\n",
    "        # can we use the relevance or simply the rank of results from lookup?\n",
    "        importance = 1\n",
    "        \n",
    "        # compute lev distance\n",
    "        lev_distance = 1 / (levenshtein_distance(phr, candidate_entity) + 1)\n",
    "        \n",
    "        # compute relevance with doc embedding\n",
    "        phr_flair = Sentence(phr)\n",
    "        self.embedding.embed(phr_flair)\n",
    "        cos_sim = 1 - spatial.distance.cosine(question_embedding, phr_flair.embedding.tolist())\n",
    "        \n",
    "        score = alfa1 * importance + alfa2 * lev_distance + alfa3 * cos_sim\n",
    "        return score\n",
    "    \n",
    "    def extract(self, question):\n",
    "        sentence = Sentence(question)\n",
    "        self.tagger.predict(sentence)\n",
    "        \n",
    "        entities = sentence.to_dict(tag_type='ner')['entities']\n",
    "        entities = [entity['text'] for entity in entities]\n",
    "        return entities\n",
    "    \n",
    "    def extend_entity(self, question, phr, max_len):\n",
    "        tmp_question = question.replace(phr, 'ENTITY')\n",
    "        # get question tokens\n",
    "        question_tokens = tmp_question.split()\n",
    "        # get position of current entity\n",
    "        index = question_tokens.index('ENTITY')\n",
    "\n",
    "        extended_entities = []\n",
    "\n",
    "        for size in range(2, max_len+1):\n",
    "            for group in self.__split_overlap(question_tokens, size, size-1):\n",
    "                print(group)\n",
    "                if 'ENTITY' in group:\n",
    "                    extended_entities.append(' '.join(group).replace('ENTITY', phr))\n",
    "        return extended_entities\n",
    "    \n",
    "    def __get_question_embedding(self, question):\n",
    "        sentence = Sentence(question)\n",
    "        self.embedding.embed(sentence)\n",
    "        return sentence.embedding.tolist()\n",
    "        \n",
    "    \n",
    "    def link(self, question, max_len = 3):\n",
    "        question_embedding = self.__get_question_embedding(question)\n",
    "        \n",
    "        entity_phrases = self.extract(question)\n",
    "        \n",
    "        candidate_entity_score = {'phr': None, 'candidate_entity': None, 'score': 0}\n",
    "        for i, phr in enumerate(entity_phrases):\n",
    "            # extend extracted entities\n",
    "            PX = self.extend_entity(question, phr, max_len)\n",
    "            EC = []\n",
    "            # look for candidate entities\n",
    "            for phr_ext in PX:\n",
    "                docs = self.__lookup(phr_ext)\n",
    "                if len(docs) > 0:\n",
    "                    EC.extend(docs)\n",
    "            \n",
    "            candidate_entity_score_tmp = {'candidate_entity': None, 'score': 0}\n",
    "            for j, candidate_entity in enumerate(EC):\n",
    "                tmp_score = self.__compute_relevance(phr, candidate_entity['label'][0], question_embedding)\n",
    "                if tmp_score > candidate_entity_score_tmp['score']:\n",
    "                    candidate_entity_score_tmp['candidate_entity'] = candidate_entity\n",
    "                    candidate_entity_score_tmp['score'] = tmp_score\n",
    "            \n",
    "            if candidate_entity_score_tmp['score'] > candidate_entity_score['score']:\n",
    "                candidate_entity_score['phr'] = phr\n",
    "                candidate_entity_score['candidate_entity'] = candidate_entity_score_tmp['candidate_entity']\n",
    "                \n",
    "        return candidate_entity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "horizontal-november",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-24 19:08:02,420 --------------------------------------------------------------------------------\n",
      "2021-04-24 19:08:02,421 The model key 'ner-fast' now maps to 'https://huggingface.co/flair/ner-english-fast' on the HuggingFace ModelHub\n",
      "2021-04-24 19:08:02,422  - The most current version of the model is automatically downloaded from there.\n",
      "2021-04-24 19:08:02,422  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/ner-fast/en-ner-fast-conll03-v0.4.pt)\n",
      "2021-04-24 19:08:02,423 --------------------------------------------------------------------------------\n",
      "2021-04-24 19:08:02,747 loading file ..\\..\\data\\flair\\models\\ner-english-fast\\4c58e7191ff952c030b82db25b3694b58800b0e722ff15427f527e1631ed6142.e13c7c4664ffe2bbfa8f1f5375bd0dced866b8c1dd7ff89a6d705518abf0a611\n"
     ]
    }
   ],
   "source": [
    "entity_linker = EntityLinker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "optional-advice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', 'love')\n",
      "('love', 'ENTITY')\n",
      "('ENTITY', '.')\n",
      "('I', 'love', 'ENTITY')\n",
      "('love', 'ENTITY', '.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'phr': 'Berlin',\n",
       " 'candidate_entity': {'score': ['102722.95'],\n",
       "  'refCount': ['4684'],\n",
       "  'resource': ['http://dbpedia.org/resource/Berlin'],\n",
       "  'redirectlabel': ['Athens on the Spree',\n",
       "   'Berlib',\n",
       "   'Berlim',\n",
       "   'Berlin, Germany',\n",
       "   'Berlin-Zentrum',\n",
       "   'Berlin.de',\n",
       "   'Berlin (Germany)',\n",
       "   'Berlin City',\n",
       "   'Berlin Germany',\n",
       "   'Berlin State',\n",
       "   'Capital of East Germany',\n",
       "   'CityBerlin',\n",
       "   'City of Berlin',\n",
       "   'Cuisine of Berlin',\n",
       "   'DEBER',\n",
       "   'Federal State of Berlin',\n",
       "   'Historical sites in berlin',\n",
       "   'Land Berlin',\n",
       "   'Silicon Allee',\n",
       "   'Spreeathen',\n",
       "   'State of Berlin',\n",
       "   'UN/LOCODE:DEBER'],\n",
       "  'typeName': ['Settlement', 'City', 'Place', 'PopulatedPlace', 'Location'],\n",
       "  'comment': [\"Berlin (; German: [bɛʁˈliːn] ()) is the capital and largest city of Germany by both area and population. Its 3,748,148 (2018) inhabitants make it the  most populous city proper of the European Union. The city is one of Germany's 16 federal states. It is surrounded by the state of Brandenburg, and contiguous with Potsdam, Brandenburg's capital. The two cities are at the center of the Berlin-Brandenburg capital region, which is, with about six million inhabitants and an area of more than 30,000 km², Germany's third-largest metropolitan region after the Rhine-Ruhr and Rhine-Main regions.\"],\n",
       "  'label': ['Berlin'],\n",
       "  'type': ['http://dbpedia.org/ontology/Settlement',\n",
       "   'http://dbpedia.org/ontology/City',\n",
       "   'http://dbpedia.org/ontology/Place',\n",
       "   'http://dbpedia.org/ontology/PopulatedPlace',\n",
       "   'http://dbpedia.org/ontology/Location'],\n",
       "  'category': ['http://dbpedia.org/resource/Category:University_towns_in_Germany',\n",
       "   'http://dbpedia.org/resource/Category:Turkish_communities_outside_Turkey',\n",
       "   'http://dbpedia.org/resource/Category:City-states',\n",
       "   'http://dbpedia.org/resource/Category:Members_of_the_Hanseatic_League',\n",
       "   'http://dbpedia.org/resource/Category:Populated_places_established_in_the_13th_century',\n",
       "   'http://dbpedia.org/resource/Category:Capitals_in_Europe',\n",
       "   'http://dbpedia.org/resource/Category:1230s_establishments_in_the_Holy_Roman_Empire',\n",
       "   'http://dbpedia.org/resource/Category:1237_establishments_in_Europe',\n",
       "   'http://dbpedia.org/resource/Category:Berlin',\n",
       "   'http://dbpedia.org/resource/Category:German_state_capitals']},\n",
       " 'score': 0}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_linker.link('I love Berlin .', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-flush",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
