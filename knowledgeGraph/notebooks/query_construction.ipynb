{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import sparql\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from Levenshtein import distance as levenshtein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = {\n",
    "    'p0': {'A': []},\n",
    "    'p1': {'A': ['B']},\n",
    "    'p2': {'A': ['B'],\n",
    "          'B': ['C']},\n",
    "    'p3': {'A': ['B'],\n",
    "          'C': ['B']},\n",
    "    'p4': {'A': ['B', 'C']},\n",
    "    'p5': {'A': ['B', 'C', 'D']},\n",
    "    'p6': {'A': ['B', 'C'],\n",
    "          'C': ['D']},\n",
    "    'p7': {'A': ['B'],\n",
    "          'B': ['C'],\n",
    "          'C': ['D']},\n",
    "    'p8': {'A': ['B'],\n",
    "          'B': ['C'],\n",
    "          'D': ['C']},\n",
    "    'p9': {'A': ['B'],\n",
    "          'B': ['C'],\n",
    "          'D': ['B']},\n",
    "    'p10': {'A': ['B'],\n",
    "           'B': ['C', 'D']},\n",
    "    'p11': {'A': ['B'],\n",
    "           'C': ['B'],\n",
    "           'D': ['B']}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusions = ['<http://dbpedia.org/property/wikiPageUsesTemplate>',\n",
    "              '<http://dbpedia.org/ontology/wikiPageExternalLink>', \n",
    "              '<http://dbpedia.org/ontology/wikiPageID>', \n",
    "              '<http://dbpedia.org/ontology/wikiPageRevisionID>', \n",
    "              '<http://dbpedia.org/ontology/wikiPageLength>', \n",
    "              '<http://dbpedia.org/ontology/wikiPageWikiLink>', \n",
    "              '<http://www.w3.org/2000/01/rdf-schema#label>', \n",
    "              '<http://www.w3.org/2002/07/owl#sameAs>', \n",
    "              '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>', \n",
    "              '<http://schema.org/sameAs>', \n",
    "              '<http://purl.org/dc/terms/subject>', \n",
    "              '<http://xmlns.com/foaf/0.1/isPrimaryTopicOf>', \n",
    "              '<http://xmlns.com/foaf/0.1/depiction>', \n",
    "              '<http://www.w3.org/2000/01/rdf-schema#seeAlso>', \n",
    "              '<http://www.w3.org/2000/01/rdf-schema#comment>', \n",
    "              '<http://dbpedia.org/ontology/abstract>', \n",
    "              '<http://dbpedia.org/ontology/thumbnail>', \n",
    "              '<http://dbpedia.org/property/caption>', \n",
    "              '<http://dbpedia.org/property/captionAlign>', \n",
    "              '<http://dbpedia.org/property/image>', \n",
    "              '<http://dbpedia.org/property/imageFlag>', \n",
    "              '<http://www.w3.org/ns/prov#wasDerivedFrom>', \n",
    "              '<http://dbpedia.org/ontology/wikiPageRedirects>', \n",
    "              '<http://dbpedia.org/ontology/wikiPageDisambiguates>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryBuilder():\n",
    "    def __init__(self):\n",
    "        self.embeddings = self.__load_embeddings()\n",
    "        self.exclusions = self.__get_exclusions()\n",
    "    \n",
    "    def build(self, question, entity, pattern):\n",
    "        cn = entity\n",
    "        # get pattern graph\n",
    "        p = self.__get_pattern(pattern)\n",
    "        # make a copy of the pattern\n",
    "        Q = p.copy()\n",
    "        # get non-intermediate nodes\n",
    "        NS = self.__get_non_intermediate_nodes(p)\n",
    "        \n",
    "        while True:\n",
    "            # empty relations set\n",
    "            R = pd.DataFrame(columns=['pred', 'label'])\n",
    "            \n",
    "            # check if there nodes or edges unlabeled\n",
    "            if self.__is_labeled(Q):\n",
    "                return Q\n",
    "            \n",
    "            # check if NS has outgoing edges\n",
    "            if self.__check_if_outgoing(NS):\n",
    "                outgoing_relations = self.__get_relations(entity=cn, query_type='outgoing')\n",
    "                # add all outgoing relation found to R\n",
    "                R = R.append(outgoing_relations)\n",
    "                \n",
    "            # check if NS has incoming edges\n",
    "            if self.__check_if_incoming(NS):\n",
    "                outgoing_relations = self.__get_relations(entity=cn, query_type='incoming')\n",
    "                # add all incoming relation found to R\n",
    "                R = R.append(outgoing_relations)\n",
    "            \n",
    "            # get r, most relevant relation to question\n",
    "            r = self.__get_most_relevant_relation(question, R)\n",
    "            \n",
    "            return r\n",
    "            \n",
    "            # if entity is in question\n",
    "            if cn in question: \n",
    "                return\n",
    "                # assemble entity and relation r in Q\n",
    "            else:\n",
    "                return\n",
    "                # assemble variable and relation r in Q\n",
    "            \n",
    "            # NS = adiacent node to explored structure\n",
    "            # cn = not sure\n",
    "        return    \n",
    "        \n",
    "    \n",
    "    def __get_pattern(self, pattern):\n",
    "        return nx.from_dict_of_lists(patterns[pattern], \n",
    "                                     create_using=nx.DiGraph)      \n",
    "    \n",
    "    def __get_non_intermediate_nodes(self, p):\n",
    "        return {node: {'in_degree': p.in_degree(node), 'out_degree': p.out_degree(node)} \n",
    "                         for node in p.nodes if p.out_degree(node) + p.in_degree(node) < 2}\n",
    "    \n",
    "    def __is_labeled(self, Q):\n",
    "        # check if nodes are labeled\n",
    "        for node in Q.nodes:\n",
    "            if not Q.nodes[node]:\n",
    "                return False\n",
    "        # check if edges are labeled\n",
    "        for _,_,e in Q.edges(data=True):\n",
    "            if not e:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def __check_if_outgoing(self, NS):\n",
    "        out_degree = [NS[node]['out_degree'] for node in NS]\n",
    "        return max(out_degree) > 0\n",
    "    \n",
    "    def __check_if_incoming(self, NS):\n",
    "        in_degree = [NS[node]['in_degree'] for node in NS]\n",
    "        return max(in_degree) > 0\n",
    "    \n",
    "    def __get_relations(self, entity, query_type, endpoint = 'http://dbpedia.org/sparql'):\n",
    "        print(query_type)\n",
    "        q = self.__get_query(entity, query_type)\n",
    "        results = sparql.query(endpoint, q)\n",
    "        \n",
    "        relations = pd.DataFrame(columns=['pred', 'label'])\n",
    "        for i, row in enumerate(results):\n",
    "            (pred, label) = sparql.unpack_row(row)\n",
    "            \n",
    "            if not label:\n",
    "                label = self.__parse_predicate(pred)\n",
    "            \n",
    "            relations = relations.append({\n",
    "                'pred': pred,\n",
    "                'label': label\n",
    "            }, ignore_index=True)\n",
    "    \n",
    "        return relations\n",
    "    \n",
    "    def __get_exclusions(self):\n",
    "        return ', '.join(exclusions)\n",
    "    \n",
    "    def __parse_predicate(self, pred):\n",
    "        last = pred.rsplit('/',1)[1]\n",
    "        splitted = re.findall(r'[A-Z]?[a-z]+|[A-Z]+(?=[A-Z]|$)', last) \n",
    "        return ' '.join(splitted)\n",
    "\n",
    "    def __get_query(self, entity, query_type):\n",
    "        if query_type == 'outgoing':\n",
    "            return \"select distinct ?pred ?pred_label_stripped \\\n",
    "                    where {  \\\n",
    "                        \"+ entity +\" ?pred ?obj.  \\\n",
    "                        OPTIONAL {  \\\n",
    "                            ?pred rdfs:label ?pred_label . \\\n",
    "                            FILTER (lang(?pred_label) = 'en').  \\\n",
    "                            BIND (STR(?pred_label)  AS ?pred_label_stripped). \\\n",
    "                        } . \\\n",
    "                        FILTER(?pred NOT IN (\"+ self.exclusions +\") ). \\\n",
    "                    }\"\n",
    "        elif query_type == 'incoming':\n",
    "            return \"select distinct ?pred ?pred_label_stripped \\\n",
    "                    where { \\\n",
    "                        ?subj ?pred dbr:Barack_Obama. \\\n",
    "                        ?pred rdfs:label ?pred_label. \\\n",
    "                        OPTIONAL {  \\\n",
    "                            ?pred rdfs:label ?pred_label . \\\n",
    "                            FILTER (lang(?pred_label) = 'en').  \\\n",
    "                            BIND (STR(?pred_label)  AS ?pred_label_stripped). \\\n",
    "                        } . \\\n",
    "                        FILTER(?pred NOT IN (\" + self.exclusions + \") ). }\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError('query_type has to be either \\'incoming\\' or \\'outgoing\\' for value:' + query_type)\n",
    "    \n",
    "    def __load_embeddings(self, path='../../data/glove.twitter.27B.200d.txt'):\n",
    "        embeddings_dict = {}\n",
    "        print('Loading embeddings...')\n",
    "        with open(path, 'r', encoding=\"utf8\") as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], \"float32\")\n",
    "                embeddings_dict[word] = vector\n",
    "        return embeddings_dict\n",
    "    \n",
    "    def __get_most_relevant_relation(self, question, R, lambda_param=0.4):\n",
    "        unique_relations = R.label.unique()\n",
    "        question = question.lower().replace('?', ' ?')\n",
    "        # tokenize question\n",
    "        question_tokens = question.split()\n",
    "        \n",
    "        relevances = []\n",
    "        \n",
    "        for relation in unique_relations:\n",
    "            # tokenize label\n",
    "            relation_tokens = relation.split()\n",
    "            \n",
    "            relevance = 0\n",
    "            for rel_token in relation_tokens:                \n",
    "                \n",
    "                for question_token in question_tokens:\n",
    "                    \n",
    "                    if rel_token in self.embeddings:\n",
    "                        \n",
    "                        rel_token_embedding = self.embeddings[rel_token]\n",
    "                        question_token_embedding = self.embeddings[question_token]\n",
    "\n",
    "                        # compute cosine similarity\n",
    "                        cos_sim = dot(rel_token_embedding, question_token_embedding) \\\n",
    "                                    /(norm(rel_token_embedding)*norm(question_token_embedding))\n",
    "                    else:\n",
    "                        cos_sim = 0\n",
    "                    # compute lev distance\n",
    "                    lev_distance = levenshtein_distance(question_token, rel_token)\n",
    "                    # sum to previous relenvances of relation tokens and question tokens\n",
    "                    relevance += lambda_param * cos_sim + (1 - lambda_param) * 1/(lev_distance+1)\n",
    "            print(relevance)\n",
    "            print(relation)\n",
    "            \n",
    "            relevances.append(relevance)\n",
    "        relevances = np.array(relevances)\n",
    "        \n",
    "        print(np.argmax(relevances))\n",
    "        \n",
    "        return unique_relations[np.argmax(relevances)]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_builder = QueryBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = query_builder.build(question='Who is the spouse of Barack Obama?', entity='dbr:Barack_Obama', pattern='p1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
